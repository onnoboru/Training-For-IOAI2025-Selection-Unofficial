

# day0
実装量やばくないけど説明料やば！教材として結構いい線行ってるんじゃね、と思ってます。 BERT の説明だけちょっとだけ不安。ベースラインを確認してくれた T.N. さんありがとう！ところで、どの解法でどれくらいスコアが出るのかとか、そもそもベースライン 20 epoch 5fold 回してどれくらいスコアが出るのかとか知りません。どうにかなる

# day1
- バッテリィズの ANN が面白かった
- ベースラインを公開した
- パスは適宜治してください
- commonlit-deberta-train と commonlit-deberta-test では debertav3 を使って提出した。 BERT のベースラインからの発展を考えると自然に出てくる発想な気がします。少なくともモデルの名前を聞いたことがある！って人は出てきてほしかったな。
- ここまでは Pytorch lightning を使っていない（ここから使います）
- ここまでは FP16 に対応させていない（ごめんなさい）

# 運営の想定
まだ何も実装してないですが、みんなが選択しそうな解法一覧予想、まずはみんながやりそうなやつから
- fine-tuning を頑張る

パラメータとかをみんなが色々いじってくれる、はず

- large に変更

これもこの発想に辿り着く人は多そう。

- BERT の埋込表現から lightgbm とか入れてアンサンブル、スタッキング

kaggle でよく見るやつ。 BERT が何を出力するモデルなのかを知っていれば、もしくは kaggle で見たことがあれば、出てきてほしい発想

- モデルを DeBERTA or RoBERTA に変更

BERT のベースラインから派生しているので、（レベル感わからないけど）今年代表を目指している人なら自然に出て来そうな発想。これを見てモデル名にピンときた人は出てきてほしい。人気がありそうなのは前者かな。ここまでの 3 つの組み合わせが「表想定解」です。

- LLM の LoRA

裏想定解。使用モデルの検討の「また、本当に BERT がベストなのでしょうか......?」というコメントの真意はこれです。 LLM や LoRA の流行前である 2021 年にやったコンペなので、それを 2024 にやったらどうなるんだろう、というのがこのコンペを選択したモチベの一つです。 LLM 得意 er はやってるかも。最近あった類似コンペとして解説で atmacup-17 の例を上げる予定ですが、ここでも LLM + LoRA が流行してた。記憶が正しければ LMSYS 帰りの kaggler がみんなそこで試してかなり成功してた。

- modenBERT 

最近話題のやつ。誰か試してくれないかなー

- 細かいテクシリーズ

AMP とか dat parallel とか高速化とか wandb とか。短いコンペなので wandb は流石にやってる人がいないかも知れない。ラッパー使ってる人は僕以外にいるのかな、 Trainer は慣れてる人が多いかもだし pytorch lightning も破壊的なバージョン変更が起こらないくらいの期間なら楽に欠ける手段としてアリな気がするけどここらへんは宗教戦争になりかねないので

- 僕が知らないテク

たくさん出てほしいなー

ということで上にあるのをできるだけ多く実装してゴリゴリアンサンブルするのが俺のやることです！楽しみ～  
などと事前に言っていました。