{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "スコア : base で 10epc 1fold 0.03768 tiny で 10epc 5fold 0.03643  \n",
                "派生 : mixup  \n",
                "追加 : convnext\n",
                "  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "if 'KAGGLE_URL_BASE' in set(os.environ.keys()) :\n",
                "    # os.environ.pop('TPU_PROCESS_ADDRESSES')\n",
                "    !pip install lightning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "cuda\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import gc\n",
                "import re\n",
                "import sys\n",
                "import time\n",
                "import copy\n",
                "import random \n",
                "import glob \n",
                "import zipfile\n",
                "import shutil\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "\n",
                "import lightning.pytorch as pl  \n",
                "from lightning.pytorch import seed_everything\n",
                "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
                "\n",
                "import timm\n",
                "import albumentations as A\n",
                "from albumentations.pytorch import ToTensorV2   \n",
                "from PIL import Image\n",
                "\n",
                "import transformers\n",
                "\n",
                "from tqdm import tqdm\n",
                "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score\n",
                "from sklearn.model_selection import KFold\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "False\n"
                    ]
                }
            ],
            "source": [
                "class CFG :\n",
                "    debug_one_epoch = False\n",
                "    debug_one_fold = False\n",
                "    only_infer = False\n",
                "    num_workers = 16\n",
                "    batch_size = 64\n",
                "    num_epochs = 10\n",
                "    lr = 1e-4\n",
                "    early_stopping_round = 5\n",
                "    warmup_prop = 0.1\n",
                "    random_seed = 42\n",
                "    n_splits = 5\n",
                "    model_name = \"convnext_tiny.in12k_ft_in1k\" # timm で使うモデル名  convnext_small.fb_in22k\n",
                "    pretrained_path = None\n",
                "    train_dir = None # 学習データセットのパス\n",
                "    test_dir = None # テストデータセットのパス\n",
                "    optimizer = torch.optim.AdamW\n",
                "    criterion = nn.BCEWithLogitsLoss()\n",
                "    scheduler = transformers.get_linear_schedule_with_warmup\n",
                "    input_imgsize = 224\n",
                "    upscale_imsize = 256\n",
                "    mixup_alpha = 1.0\n",
                "    mixup_finish_epoch = 5\n",
                "    data_dir = \"../input/dogs-vs-cats-redux-kernels-edition/\"\n",
                "    kaggle_working_dir = \"/kaggle/working/\"\n",
                "  \n",
                "def seed_torch(seed):\n",
                "    random.seed(seed)\n",
                "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    torch.cuda.manual_seed(seed)\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "    \n",
                "seed_torch(CFG.random_seed)\n",
                "\n",
                "if  CFG.debug_one_epoch :\n",
                "    CFG.num_epochs = 1\n",
                "\n",
                "print('KAGGLE_URL_BASE' in set(os.environ.keys()))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "submission = pd.read_csv(os.path.join(CFG.data_dir, \"sample_submission.csv\"))\n",
                "if 'KAGGLE_URL_BASE' in set(os.environ.keys()) :\n",
                "    kaggle_train_dir = os.path.join(CFG.kaggle_working_dir, \"train\")\n",
                "    # すでに解凍されている場合は解凍しない\n",
                "    if not os.path.exists(kaggle_train_dir) :\n",
                "        shutil.unpack_archive(os.path.join(CFG.data_dir, \"train.zip\"), CFG.kaggle_working_dir)\n",
                "    \n",
                "    kaggle_test_dir = os.path.join(CFG.kaggle_working_dir, \"test\")\n",
                "    if not os.path.exists(kaggle_test_dir) :\n",
                "        shutil.unpack_archive(os.path.join(CFG.data_dir, \"test.zip\"), CFG.kaggle_working_dir)\n",
                "        \n",
                "    CFG.data_dir = CFG.kaggle_working_dir\n",
                "    \n",
                "CFG.train_dir = os.path.join(CFG.data_dir, \"train\")\n",
                "CFG.test_dir = os.path.join(CFG.data_dir, \"test\")\n",
                "\n",
                "train_list = glob.glob(os.path.join(CFG.data_dir, \"train\", \"*.jpg\"))\n",
                "test_list = glob.glob(os.path.join(CFG.data_dir, \"test\", \"*.jpg\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df = pd.DataFrame(train_list, columns=[\"path\"])\n",
                "train_df[\"class\"] = train_df[\"path\"].apply(lambda x : x.split(\"/\")[-1].split(\".\")[0])\n",
                "train_df[\"class\"] = train_df[\"class\"].map({\"dog\" : 1, \"cat\" : 0})\n",
                "test_df = pd.DataFrame(test_list, columns=[\"path\"])\n",
                "test_df[\"class\"] = -1\n",
                "# test_df に対しては path の数字が昇順であることを保証するために id を追加\n",
                "test_df[\"id\"] = test_df[\"path\"].apply(lambda x : int(x.split(\"/\")[-1].split(\".\")[0]))\n",
                "test_df = test_df.sort_values(\"id\").reset_index(drop=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_transform = A.Compose([\n",
                "    A.Resize(CFG.upscale_imsize, CFG.upscale_imsize),\n",
                "    A.RandomCrop(CFG.input_imgsize, CFG.input_imgsize),\n",
                "    A.HorizontalFlip(p=0.5),\n",
                "    A.RandomBrightnessContrast(p=0.5),\n",
                "    A.Normalize(),\n",
                "    ToTensorV2()\n",
                "])\n",
                "test_transform = A.Compose([\n",
                "    A.Resize(CFG.upscale_imsize, CFG.upscale_imsize),\n",
                "    A.CenterCrop(CFG.input_imgsize, CFG.input_imgsize),\n",
                "    A.Normalize(),\n",
                "    ToTensorV2()\n",
                "])\n",
                "tta_a_transform = A.Compose([\n",
                "    A.Resize(CFG.upscale_imsize, CFG.upscale_imsize),\n",
                "    A.CenterCrop(CFG.input_imgsize, CFG.input_imgsize),\n",
                "    A.HorizontalFlip(p=1.0),\n",
                "    A.Normalize(),\n",
                "    ToTensorV2()\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DogsCatsDataset(Dataset) :\n",
                "    def __init__(self, df, transform=None) :\n",
                "        self.df = df # さっきの pandas dataframe を受け取る\n",
                "        self.transform = transform # 画像の変換処理を受け取る\n",
                "\n",
                "    def __len__(self) :\n",
                "        return len(self.df)\n",
                "    \n",
                "    def __getitem__(self, idx) :\n",
                "        img = Image.open(self.df.iloc[idx, 0])\n",
                "        img = self.transform(image = np.array(img))[\"image\"]\n",
                "        label = self.df.iloc[idx, 1].astype(np.float32)\n",
                "        return img, label"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "class GeM(nn.Module) :\n",
                "    def __init__(self, p=3, eps=1e-6) :\n",
                "        super(GeM, self).__init__()\n",
                "        self.p = nn.Parameter(torch.ones(1)*p)\n",
                "        self.eps = eps\n",
                "        \n",
                "    def forward(self, x) :\n",
                "        return self.gem(x, p=self.p, eps=self.eps)\n",
                "    \n",
                "    def gem(self, x, p=3, eps=1e-6) :\n",
                "        return nn.functional.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DogCatModel(nn.Module) :\n",
                "    def __init__(self) :\n",
                "        super(DogCatModel, self).__init__()\n",
                "        self.model = timm.create_model(CFG.model_name, pretrained=True,num_classes=0,global_pool = \"\") # (bs,c,h,w)\n",
                "        self.model.global_pool = nn.Identity()\n",
                "        self.pool = GeM()\n",
                "        self.fc1 = nn.Linear(self.model.num_features, 1)\n",
                "        \n",
                "    def forward(self, x) :\n",
                "        x = self.model(x)\n",
                "        x = self.pool(x).squeeze(3).squeeze(2)\n",
                "        x = self.fc1(x)\n",
                "        return x"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "class dog_vs_cats_pl_model(pl.LightningModule) :\n",
                "    def __init__(self, model) :\n",
                "        super(dog_vs_cats_pl_model, self).__init__()\n",
                "        self.model = model\n",
                "        self.criterion = CFG.criterion\n",
                "        \n",
                "    def forward(self, x) :\n",
                "        return self.model(x)\n",
                "    \n",
                "    def training_step(self, batch, batch_idx) :\n",
                "        img, label = batch\n",
                "        # 6epoch 目までは mixup\n",
                "        # timm で簡単に書き直せるらしいので、 todo\n",
                "        if self.current_epoch < CFG.mixup_finish_epoch :\n",
                "            mixup_alpha = CFG.mixup_alpha\n",
                "            lam = np.random.beta(mixup_alpha, mixup_alpha)\n",
                "            index = torch.randperm(img.size(0))\n",
                "            img = lam*img + (1-lam)*img[index]\n",
                "            label = lam*label + (1-lam)*label[index]\n",
                "            \n",
                "        output = self(img)\n",
                "        loss = self.criterion(output.squeeze(-1), label)\n",
                "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
                "        self.log(\"lr\", self.trainer.optimizers[0].param_groups[0][\"lr\"], on_step=True, on_epoch=False, prog_bar=True, logger=True)\n",
                "        return loss\n",
                "    \n",
                "    def validation_step(self, batch, batch_idx) :\n",
                "        img, label = batch\n",
                "        output = self(img)\n",
                "        loss = self.criterion(output.squeeze(-1), label)\n",
                "        self.log(\"valid_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
                "        return loss\n",
                "    \n",
                "    def predict_step(self, batch, batch_idx) :\n",
                "        img, _ = batch\n",
                "        output = self(img)\n",
                "        output = torch.sigmoid(output).cpu().numpy()\n",
                "        return output\n",
                "        \n",
                "    \n",
                "    def configure_optimizers(self) :\n",
                "        optimizer = CFG.optimizer(self.parameters(), lr=CFG.lr)\n",
                "        num_training_steps = len(self.train_dataloader)*CFG.num_epochs\n",
                "        num_warmup_steps = int(num_training_steps * CFG.warmup_prop)\n",
                "        scheduler = {\n",
                "            \"scheduler\" :  transformers.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps),\n",
                "            \"interval\" : \"step\",\n",
                "            \"frequency\" : 1\n",
                "        }\n",
                "        \n",
                "        return [optimizer], [scheduler]\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_train_cv_pl(train, test):\n",
                "    kf = KFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.random_seed)\n",
                "    oof = np.zeros((len(train), 1)) \n",
                "    predictions =[]\n",
                "    test_df = test.copy()\n",
                "    for fold, (train_idx, valid_idx) in enumerate(kf.split(train)) :\n",
                "        print(f\"====================fold : {fold}====================\")\n",
                "        train_df = train.iloc[train_idx].reset_index(drop=True)\n",
                "        valid_df = train.iloc[valid_idx].reset_index(drop=True)\n",
                "        \n",
                "        train_dataset = DogsCatsDataset(train_df, transform=train_transform)\n",
                "        valid_dataset = DogsCatsDataset(valid_df, transform=test_transform)\n",
                "        test_dataset = DogsCatsDataset(test_df, transform=test_transform)\n",
                "        tta_a_dataset = DogsCatsDataset(test_df, transform=tta_a_transform)\n",
                "        \n",
                "        train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers, drop_last=True, pin_memory=True)\n",
                "        valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
                "        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
                "        tta_a_loader = DataLoader(tta_a_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
                "        \n",
                "        model = DogCatModel()\n",
                "        lightning_model = dog_vs_cats_pl_model(model)\n",
                "        lightning_model.train_dataloader = train_loader\n",
                "        lightning_model.valid_dataloader = valid_loader\n",
                "\n",
                "        early_stopping = EarlyStopping(\n",
                "            monitor=\"valid_loss\",\n",
                "            mode=\"min\", \n",
                "            patience=CFG.early_stopping_round,\n",
                "        )\n",
                "        checkpoint = ModelCheckpoint(\n",
                "            monitor=\"valid_loss\", \n",
                "            mode=\"min\", \n",
                "            dirpath=\"checkpoints\", \n",
                "            filename=f\"{CFG.model_name}_fold{fold}\", \n",
                "            save_top_k=1,\n",
                "        )\n",
                "        seed_everything(CFG.random_seed)\n",
                "        logger = pl.loggers.TensorBoardLogger(\"logs\", name=f\"{CFG.model_name}_fold{fold}\")\n",
                "        trainer = pl.Trainer(max_epochs=CFG.num_epochs, accelerator=\"gpu\", precision=\"16-mixed\", logger=logger, callbacks=[early_stopping, checkpoint])\n",
                "        trainer.fit(lightning_model, train_loader, valid_loader)\n",
                "\n",
                "        # best_model = DogCatModel()\n",
                "        # best_model.load_state_dict(torch.load(os.path.join(\"checkpoints\", f\"{CFG.model_name}_fold{fold}.ckpt\"))[\"state_dict\"])\n",
                "        # best_model.eval()\n",
                "        \n",
                "        valid_preds_list = trainer.predict(lightning_model, valid_loader)\n",
                "        valid_preds_arr = np.concatenate(valid_preds_list)\n",
                "        oof[valid_idx] = valid_preds_arr\n",
                "        \n",
                "        test_preds_list = trainer.predict(lightning_model, test_loader)\n",
                "        test_preds_arr = np.concatenate(test_preds_list)\n",
                "        \n",
                "        tta_a_preds_list = trainer.predict(lightning_model, tta_a_loader)\n",
                "        tta_a_preds_arr = np.concatenate(tta_a_preds_list)\n",
                "        \n",
                "        test_preds_arr = (test_preds_arr + tta_a_preds_arr) / 2\n",
                "        \n",
                "        predictions.append(test_preds_arr)\n",
                "        \n",
                "        del model, lightning_model, trainer\n",
                "        gc.collect()\n",
                "        # torch.cuda.empty_cache()\n",
                "        \n",
                "        if CFG.debug_one_fold :\n",
                "            break\n",
                "    \n",
                "    predictions = np.mean(predictions, axis=0)\n",
                "    \n",
                "    return {\n",
                "        \"oof\" : oof,\n",
                "        \"predictions\" : predictions\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "====================fold : 0====================\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Seed set to 42\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Using 16bit Automatic Mixed Precision (AMP)\n",
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "\n",
                        "  | Name      | Type              | Params | Mode \n",
                        "--------------------------------------------------------\n",
                        "0 | model     | DogCatModel       | 4.0 M  | train\n",
                        "1 | criterion | BCEWithLogitsLoss | 0      | train\n",
                        "--------------------------------------------------------\n",
                        "4.0 M     Trainable params\n",
                        "0         Non-trainable params\n",
                        "4.0 M     Total params\n",
                        "16.035    Total estimated model params size (MB)\n",
                        "339       Modules in train mode\n",
                        "0         Modules in eval mode\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 0: 100%|██████████| 312/312 [01:16<00:00,  4.09it/s, v_num=0, train_loss_step=0.0225, lr=3.12e-8, valid_loss_step=0.000988, valid_loss_epoch=0.0256, train_loss_epoch=0.0796]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 0: 100%|██████████| 312/312 [01:16<00:00,  4.07it/s, v_num=0, train_loss_step=0.0225, lr=3.12e-8, valid_loss_step=0.000988, valid_loss_epoch=0.0256, train_loss_epoch=0.0796]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 79/79 [00:06<00:00, 12.52it/s]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 196/196 [00:15<00:00, 12.77it/s]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 196/196 [00:16<00:00, 11.98it/s]\n",
                        "====================fold : 1====================\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Seed set to 42\n",
                        "Using 16bit Automatic Mixed Precision (AMP)\n",
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "\n",
                        "  | Name      | Type              | Params | Mode \n",
                        "--------------------------------------------------------\n",
                        "0 | model     | DogCatModel       | 4.0 M  | train\n",
                        "1 | criterion | BCEWithLogitsLoss | 0      | train\n",
                        "--------------------------------------------------------\n",
                        "4.0 M     Trainable params\n",
                        "0         Non-trainable params\n",
                        "4.0 M     Total params\n",
                        "16.035    Total estimated model params size (MB)\n",
                        "339       Modules in train mode\n",
                        "0         Modules in eval mode\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 0: 100%|██████████| 312/312 [01:10<00:00,  4.40it/s, v_num=0, train_loss_step=0.0311, lr=3.12e-8, valid_loss_step=0.00231, valid_loss_epoch=0.0305, train_loss_epoch=0.0796]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 0: 100%|██████████| 312/312 [01:11<00:00,  4.38it/s, v_num=0, train_loss_step=0.0311, lr=3.12e-8, valid_loss_step=0.00231, valid_loss_epoch=0.0305, train_loss_epoch=0.0796]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 79/79 [00:07<00:00, 11.00it/s]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 196/196 [00:15<00:00, 12.65it/s]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 196/196 [00:17<00:00, 11.44it/s]\n",
                        "====================fold : 2====================\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Seed set to 42\n",
                        "Using 16bit Automatic Mixed Precision (AMP)\n",
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "\n",
                        "  | Name      | Type              | Params | Mode \n",
                        "--------------------------------------------------------\n",
                        "0 | model     | DogCatModel       | 4.0 M  | train\n",
                        "1 | criterion | BCEWithLogitsLoss | 0      | train\n",
                        "--------------------------------------------------------\n",
                        "4.0 M     Trainable params\n",
                        "0         Non-trainable params\n",
                        "4.0 M     Total params\n",
                        "16.035    Total estimated model params size (MB)\n",
                        "339       Modules in train mode\n",
                        "0         Modules in eval mode\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 0: 100%|██████████| 312/312 [01:09<00:00,  4.47it/s, v_num=0, train_loss_step=0.0691, lr=3.12e-8, valid_loss_step=0.0391, valid_loss_epoch=0.0278, train_loss_epoch=0.0796]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 0: 100%|██████████| 312/312 [01:10<00:00,  4.43it/s, v_num=0, train_loss_step=0.0691, lr=3.12e-8, valid_loss_step=0.0391, valid_loss_epoch=0.0278, train_loss_epoch=0.0796]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 79/79 [00:07<00:00, 10.60it/s]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 196/196 [00:15<00:00, 12.33it/s]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 196/196 [00:16<00:00, 11.61it/s]\n",
                        "====================fold : 3====================\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Seed set to 42\n",
                        "Using 16bit Automatic Mixed Precision (AMP)\n",
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "\n",
                        "  | Name      | Type              | Params | Mode \n",
                        "--------------------------------------------------------\n",
                        "0 | model     | DogCatModel       | 4.0 M  | train\n",
                        "1 | criterion | BCEWithLogitsLoss | 0      | train\n",
                        "--------------------------------------------------------\n",
                        "4.0 M     Trainable params\n",
                        "0         Non-trainable params\n",
                        "4.0 M     Total params\n",
                        "16.035    Total estimated model params size (MB)\n",
                        "339       Modules in train mode\n",
                        "0         Modules in eval mode\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 0: 100%|██████████| 312/312 [01:07<00:00,  4.60it/s, v_num=0, train_loss_step=0.0288, lr=3.12e-8, valid_loss_step=0.000239, valid_loss_epoch=0.0356, train_loss_epoch=0.0747]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 0: 100%|██████████| 312/312 [01:08<00:00,  4.56it/s, v_num=0, train_loss_step=0.0288, lr=3.12e-8, valid_loss_step=0.000239, valid_loss_epoch=0.0356, train_loss_epoch=0.0747]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 79/79 [00:06<00:00, 11.58it/s]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 196/196 [00:17<00:00, 11.22it/s]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 196/196 [00:18<00:00, 10.87it/s]\n",
                        "====================fold : 4====================\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Seed set to 42\n",
                        "Using 16bit Automatic Mixed Precision (AMP)\n",
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "\n",
                        "  | Name      | Type              | Params | Mode \n",
                        "--------------------------------------------------------\n",
                        "0 | model     | DogCatModel       | 4.0 M  | train\n",
                        "1 | criterion | BCEWithLogitsLoss | 0      | train\n",
                        "--------------------------------------------------------\n",
                        "4.0 M     Trainable params\n",
                        "0         Non-trainable params\n",
                        "4.0 M     Total params\n",
                        "16.035    Total estimated model params size (MB)\n",
                        "339       Modules in train mode\n",
                        "0         Modules in eval mode\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 0: 100%|██████████| 312/312 [01:08<00:00,  4.55it/s, v_num=0, train_loss_step=0.0347, lr=3.12e-8, valid_loss_step=0.00263, valid_loss_epoch=0.0301, train_loss_epoch=0.077]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 0: 100%|██████████| 312/312 [01:09<00:00,  4.52it/s, v_num=0, train_loss_step=0.0347, lr=3.12e-8, valid_loss_step=0.00263, valid_loss_epoch=0.0301, train_loss_epoch=0.077]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 79/79 [00:06<00:00, 11.81it/s]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 196/196 [00:16<00:00, 11.79it/s]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting DataLoader 0: 100%|██████████| 196/196 [00:17<00:00, 11.53it/s]\n",
                        "oof log loss : 0.033991093324274024\n"
                    ]
                }
            ],
            "source": [
                "def main() :\n",
                "    if CFG.only_infer :\n",
                "        test_dataset = DogsCatsDataset(test_df, transform=test_transform)\n",
                "        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
                "        model = DogCatModel()\n",
                "        lightning_model = dog_vs_cats_pl_model(model)\n",
                "        predictions = []\n",
                "        for fold in range(CFG.n_splits) :\n",
                "            model = lightning_model.load_from_checkpoint(f\"checkpoints/{CFG.model_name}_fold{fold}.ckpt\")\n",
                "            trainer = pl.Trainer(accelerator=\"gpu\", precision=\"16-mixed\", logger=False)\n",
                "            predictions.append(trainer.predict(model, test_loader))\n",
                "        submission[\"label\"] = np.mean(predictions, axis=0)\n",
                "        submission.to_csv(\"submission.csv\", index=False)\n",
                "        \n",
                "    else :\n",
                "        result = run_train_cv_pl(train_df, test_df)\n",
                "        oof_preds = result[\"oof\"]\n",
                "        predictions = result[\"predictions\"]\n",
                "        submission[\"label\"] = predictions\n",
                "        submission.to_csv(\"submission.csv\", index=False)\n",
                "        train_df[\"oof_preds\"] = oof_preds   \n",
                "        train_df.to_csv(\"oof_preds.csv\", index=False)\n",
                "        if CFG.debug_one_fold == False :\n",
                "            print(f\"oof log loss : {log_loss(train_df['class'], oof_preds)}\")\n",
                "        \n",
                "if __name__ == \"__main__\" :\n",
                "    main()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "submission = pd.read_csv('submission.csv')\n",
                "submission['label'] = submission['label'].clip(0.01, 0.99)\n",
                "submission.to_csv('submission_clip.csv', index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
